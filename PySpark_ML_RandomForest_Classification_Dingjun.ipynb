{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjDgeJHw/IPt7zrA6cPR3s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dingjun6953/Accelerate-Python-codes-using-proper-libraries/blob/main/PySpark_ML_RandomForest_Classification_Dingjun.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDcwVtLuM5Tz",
        "outputId": "ae7ffb5b-b3e8-4daf-93e2-1c63b3473baf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824028 sha256=6270199ad827b3d29c62ea9be3895db96953ecbc233e0b2acb1ec8c45120667a\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/e3/9b/0525ce8a69478916513509d43693511463c6468db0de237c86\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd "
      ],
      "metadata": {
        "id": "QWC-wnAjM5-0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df_iris['label'] = pd.Series(iris.target)\n",
        " \n",
        "print(df_iris.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYJWVfZ0M6Bs",
        "outputId": "c4b2bbd0-9631-490a-aa2a-133e84c079d2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
            "0                5.1               3.5                1.4               0.2   \n",
            "1                4.9               3.0                1.4               0.2   \n",
            "2                4.7               3.2                1.3               0.2   \n",
            "3                4.6               3.1                1.5               0.2   \n",
            "4                5.0               3.6                1.4               0.2   \n",
            "\n",
            "   label  \n",
            "0      0  \n",
            "1      0  \n",
            "2      0  \n",
            "3      0  \n",
            "4      0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc = SparkContext().getOrCreate()\n",
        "sqlContext = SQLContext(sc)\n",
        "\n",
        "data = sqlContext.createDataFrame(df_iris)\n",
        "print(data.printSchema()) \n",
        " \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9mTog6qM6Ej",
        "outputId": "5e7eb926-4858-40ce-80da-cf08318def85"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- sepal length (cm): double (nullable = true)\n",
            " |-- sepal width (cm): double (nullable = true)\n",
            " |-- petal length (cm): double (nullable = true)\n",
            " |-- petal width (cm): double (nullable = true)\n",
            " |-- label: long (nullable = true)\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = iris.feature_names\n",
        "\n",
        "va = VectorAssembler(inputCols = features, outputCol='features')\n",
        "\n",
        "va_df = va.transform(data)\n",
        "va_df = va_df.select(['features', 'label'])\n",
        "va_df.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugryWPFfM6HT",
        "outputId": "4e38caab-727b-4cd9-b328-09ac31814124"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+\n",
            "|         features|label|\n",
            "+-----------------+-----+\n",
            "|[5.1,3.5,1.4,0.2]|    0|\n",
            "|[4.9,3.0,1.4,0.2]|    0|\n",
            "|[4.7,3.2,1.3,0.2]|    0|\n",
            "+-----------------+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train, test) = va_df.randomSplit([0.8, 0.2])"
      ],
      "metadata": {
        "id": "sUm_662oM6KD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfc = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
        "rfc = rfc.fit(train)\n",
        "\n",
        "pred = rfc.transform(test)\n",
        "pred.show(3) \n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-QolfXIM6Mr",
        "outputId": "58d62e99-0be4-4fb5-985a-3d4aee2225b0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+--------------+-------------+----------+\n",
            "|         features|label| rawPrediction|  probability|prediction|\n",
            "+-----------------+-----+--------------+-------------+----------+\n",
            "|[4.6,3.1,1.5,0.2]|    0|[20.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|[4.8,3.1,1.6,0.2]|    0|[20.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|[4.8,3.4,1.6,0.2]|    0|[20.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "+-----------------+-----+--------------+-------------+----------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator=MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
        "acc = evaluator.evaluate(pred)\n",
        " \n",
        "print(\"Prediction Accuracy: \", acc)\n",
        " \n",
        "y_pred=pred.select(\"prediction\").collect()\n",
        "y_orig=pred.select(\"label\").collect()\n",
        "\n",
        "cm = confusion_matrix(y_orig, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMriQzqvM6Pj",
        "outputId": "47cf5046-9731-4f75-d484-c39d54dc41ef"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction Accuracy:  1.0\n",
            "Confusion Matrix:\n",
            "[[ 8  0  0]\n",
            " [ 0 13  0]\n",
            " [ 0  0 12]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kUlyOMa4M6Sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nVMsroZHM6VP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5WhonFFfM6YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "acn4b2U9M6az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r9lOMcmrM6dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kbc8dvlAM6gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RcU8J23aM6jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "03xkwdTzM6mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6vAhQ0GlM6p4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ITPCRsmVM6sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iaZhfdw-M6vZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
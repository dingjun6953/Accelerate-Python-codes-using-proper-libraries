{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAGncM2Ur6E17xKLRfV+96",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dingjun6953/Accelerate-Python-codes-using-proper-libraries/blob/main/PySpark_ML_DecisionTree_Classification_Dingjun.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjOvZ3pCLFcV",
        "outputId": "3072ce3e-e77a-4b3c-ce52-2bbc0c4add3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824028 sha256=4dffd955a50f6cbb68bde1059dfaaddb5989dc11d61e002c0375c702f67c6290\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/e3/9b/0525ce8a69478916513509d43693511463c6468db0de237c86\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd "
      ],
      "metadata": {
        "id": "On5prENsLF81"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "df_iris['label'] = pd.Series(iris.target)\n",
        " \n",
        "print(df_iris.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Px1BUeELF_z",
        "outputId": "346f4b7b-305d-41b0-93d5-c8f056da943d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
            "0                5.1               3.5                1.4               0.2   \n",
            "1                4.9               3.0                1.4               0.2   \n",
            "2                4.7               3.2                1.3               0.2   \n",
            "3                4.6               3.1                1.5               0.2   \n",
            "4                5.0               3.6                1.4               0.2   \n",
            "\n",
            "   label  \n",
            "0      0  \n",
            "1      0  \n",
            "2      0  \n",
            "3      0  \n",
            "4      0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_iris.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T7wIzDBLGCz",
        "outputId": "66fab26d-c041-4207-f2f5-6f01852847bc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc = SparkContext().getOrCreate()\n",
        "sqlContext = SQLContext(sc)\n",
        "\n",
        "data = sqlContext.createDataFrame(df_iris)\n",
        "print(data.printSchema()) \n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHoDCo-zLGFT",
        "outputId": "08a48dd4-b340-4b22-c0db-03de85d6e521"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- sepal length (cm): double (nullable = true)\n",
            " |-- sepal width (cm): double (nullable = true)\n",
            " |-- petal length (cm): double (nullable = true)\n",
            " |-- petal width (cm): double (nullable = true)\n",
            " |-- label: long (nullable = true)\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = iris.feature_names\n",
        "\n",
        "va = VectorAssembler(inputCols = features, outputCol='features')\n",
        "\n",
        "va_df = va.transform(data)\n",
        "va_df = va_df.select(['features', 'label'])\n",
        "va_df.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43gltdF2LGID",
        "outputId": "cc7fc390-1c26-40da-e384-f901859e802a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+\n",
            "|         features|label|\n",
            "+-----------------+-----+\n",
            "|[5.1,3.5,1.4,0.2]|    0|\n",
            "|[4.9,3.0,1.4,0.2]|    0|\n",
            "|[4.7,3.2,1.3,0.2]|    0|\n",
            "+-----------------+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train, test) = va_df.randomSplit([0.8, 0.2])"
      ],
      "metadata": {
        "id": "RZhcaimrLGLE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtc = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
        "dtc = dtc.fit(train)\n",
        "\n",
        "pred = dtc.transform(test)\n",
        "pred.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxPZWx9kLGOD",
        "outputId": "59ae22f0-4356-4af3-9e69-a430927c2a18"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+--------------+-------------+----------+\n",
            "|         features|label| rawPrediction|  probability|prediction|\n",
            "+-----------------+-----+--------------+-------------+----------+\n",
            "|[4.6,3.4,1.4,0.3]|    0|[41.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|[5.0,3.0,1.6,0.2]|    0|[41.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "|[5.0,3.2,1.2,0.2]|    0|[41.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
            "+-----------------+-----+--------------+-------------+----------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator=MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
        "acc = evaluator.evaluate(pred)\n",
        " \n",
        "print(\"Prediction Accuracy: \", acc)\n",
        " \n",
        "y_pred=pred.select(\"prediction\").collect()\n",
        "y_orig=pred.select(\"label\").collect()\n",
        "\n",
        "cm = confusion_matrix(y_orig, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQQmAs7uLGQ3",
        "outputId": "180fbdea-43e1-4f06-f8be-0e02db0247f6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction Accuracy:  0.9656036643332468\n",
            "Confusion Matrix:\n",
            "[[ 9  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  1 10]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aycpT8IVLGTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5YvUadtdLGWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tIvfLmw5LGZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4e0467sHLGcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uONN52EwLGfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lvr1W-QOLGiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XtC2T3KHLGlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aAnwGGSALGob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dzyW4wQiLGrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1xMhrEJ3LGvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i-Lb6BB_LGzD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}